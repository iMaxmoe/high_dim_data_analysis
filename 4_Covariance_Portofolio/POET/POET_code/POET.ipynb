{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to implement POET model to estimate the covariance matrix for of the stock data with higer accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the data:  (50, 366)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1/1/16</th>\n",
       "      <th>1/2/16</th>\n",
       "      <th>1/3/16</th>\n",
       "      <th>1/4/16</th>\n",
       "      <th>1/5/16</th>\n",
       "      <th>1/6/16</th>\n",
       "      <th>1/7/16</th>\n",
       "      <th>1/8/16</th>\n",
       "      <th>1/9/16</th>\n",
       "      <th>1/10/16</th>\n",
       "      <th>...</th>\n",
       "      <th>12/22/16</th>\n",
       "      <th>12/23/16</th>\n",
       "      <th>12/24/16</th>\n",
       "      <th>12/25/16</th>\n",
       "      <th>12/26/16</th>\n",
       "      <th>12/27/16</th>\n",
       "      <th>12/28/16</th>\n",
       "      <th>12/29/16</th>\n",
       "      <th>12/30/16</th>\n",
       "      <th>12/31/16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>26.54</td>\n",
       "      <td>26.54</td>\n",
       "      <td>26.54</td>\n",
       "      <td>26.14</td>\n",
       "      <td>26.23</td>\n",
       "      <td>26.29</td>\n",
       "      <td>26.24</td>\n",
       "      <td>25.90</td>\n",
       "      <td>25.90</td>\n",
       "      <td>25.90</td>\n",
       "      <td>...</td>\n",
       "      <td>41.67</td>\n",
       "      <td>42.16</td>\n",
       "      <td>42.16</td>\n",
       "      <td>42.16</td>\n",
       "      <td>42.16</td>\n",
       "      <td>42.65</td>\n",
       "      <td>41.84</td>\n",
       "      <td>42.33</td>\n",
       "      <td>42.94</td>\n",
       "      <td>42.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>24.94</td>\n",
       "      <td>24.94</td>\n",
       "      <td>24.94</td>\n",
       "      <td>24.76</td>\n",
       "      <td>24.84</td>\n",
       "      <td>24.99</td>\n",
       "      <td>24.62</td>\n",
       "      <td>24.69</td>\n",
       "      <td>24.69</td>\n",
       "      <td>24.69</td>\n",
       "      <td>...</td>\n",
       "      <td>38.60</td>\n",
       "      <td>38.75</td>\n",
       "      <td>38.75</td>\n",
       "      <td>38.75</td>\n",
       "      <td>38.75</td>\n",
       "      <td>39.10</td>\n",
       "      <td>38.00</td>\n",
       "      <td>38.10</td>\n",
       "      <td>38.20</td>\n",
       "      <td>38.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>41.95</td>\n",
       "      <td>41.95</td>\n",
       "      <td>41.95</td>\n",
       "      <td>40.50</td>\n",
       "      <td>40.79</td>\n",
       "      <td>41.35</td>\n",
       "      <td>40.49</td>\n",
       "      <td>40.46</td>\n",
       "      <td>40.46</td>\n",
       "      <td>40.46</td>\n",
       "      <td>...</td>\n",
       "      <td>45.28</td>\n",
       "      <td>45.64</td>\n",
       "      <td>45.64</td>\n",
       "      <td>45.64</td>\n",
       "      <td>45.64</td>\n",
       "      <td>46.05</td>\n",
       "      <td>45.32</td>\n",
       "      <td>45.68</td>\n",
       "      <td>45.56</td>\n",
       "      <td>45.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>27.70</td>\n",
       "      <td>27.70</td>\n",
       "      <td>27.70</td>\n",
       "      <td>26.39</td>\n",
       "      <td>26.82</td>\n",
       "      <td>27.25</td>\n",
       "      <td>27.14</td>\n",
       "      <td>27.44</td>\n",
       "      <td>27.44</td>\n",
       "      <td>27.44</td>\n",
       "      <td>...</td>\n",
       "      <td>31.84</td>\n",
       "      <td>31.77</td>\n",
       "      <td>31.77</td>\n",
       "      <td>31.77</td>\n",
       "      <td>31.77</td>\n",
       "      <td>32.56</td>\n",
       "      <td>31.95</td>\n",
       "      <td>31.92</td>\n",
       "      <td>31.94</td>\n",
       "      <td>31.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>4.80</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.78</td>\n",
       "      <td>4.64</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.53</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.55</td>\n",
       "      <td>...</td>\n",
       "      <td>5.55</td>\n",
       "      <td>5.60</td>\n",
       "      <td>5.60</td>\n",
       "      <td>5.60</td>\n",
       "      <td>5.60</td>\n",
       "      <td>5.60</td>\n",
       "      <td>5.30</td>\n",
       "      <td>5.15</td>\n",
       "      <td>5.50</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    1/1/16  1/2/16  1/3/16  1/4/16  1/5/16  1/6/16  1/7/16  1/8/16  1/9/16  \\\n",
       "45   26.54   26.54   26.54   26.14   26.23   26.29   26.24   25.90   25.90   \n",
       "46   24.94   24.94   24.94   24.76   24.84   24.99   24.62   24.69   24.69   \n",
       "47   41.95   41.95   41.95   40.50   40.79   41.35   40.49   40.46   40.46   \n",
       "48   27.70   27.70   27.70   26.39   26.82   27.25   27.14   27.44   27.44   \n",
       "49    4.80    4.80    4.80    4.78    4.64    4.63    4.53    4.55    4.55   \n",
       "\n",
       "    1/10/16    ...     12/22/16  12/23/16  12/24/16  12/25/16  12/26/16  \\\n",
       "45    25.90    ...        41.67     42.16     42.16     42.16     42.16   \n",
       "46    24.69    ...        38.60     38.75     38.75     38.75     38.75   \n",
       "47    40.46    ...        45.28     45.64     45.64     45.64     45.64   \n",
       "48    27.44    ...        31.84     31.77     31.77     31.77     31.77   \n",
       "49     4.55    ...         5.55      5.60      5.60      5.60      5.60   \n",
       "\n",
       "    12/27/16  12/28/16  12/29/16  12/30/16  12/31/16  \n",
       "45     42.65     41.84     42.33     42.94     42.94  \n",
       "46     39.10     38.00     38.10     38.20     38.20  \n",
       "47     46.05     45.32     45.68     45.56     45.56  \n",
       "48     32.56     31.95     31.92     31.94     31.94  \n",
       "49      5.60      5.30      5.15      5.50      5.50  \n",
       "\n",
       "[5 rows x 366 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data: The annual daily pricing data for 50 stocks over period Jan 1st - Dec 31 (2010). n = 252 (workdays in 2010)\n",
    "p1 = pd.read_csv(\"POET_prices1.csv\")\n",
    "p2 = pd.read_csv(\"POET_prices2.csv\")\n",
    "prices = pd.concat([p1,p2],axis=1)\n",
    "prices = prices.dropna(how='any')\n",
    "print(\"Dimension of the data: \", prices.shape)\n",
    "prices.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the data:  (50, 252)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1/4/16</th>\n",
       "      <th>1/5/16</th>\n",
       "      <th>1/6/16</th>\n",
       "      <th>1/7/16</th>\n",
       "      <th>1/8/16</th>\n",
       "      <th>1/11/16</th>\n",
       "      <th>1/12/16</th>\n",
       "      <th>1/13/16</th>\n",
       "      <th>1/14/16</th>\n",
       "      <th>1/15/16</th>\n",
       "      <th>...</th>\n",
       "      <th>12/16/16</th>\n",
       "      <th>12/19/16</th>\n",
       "      <th>12/20/16</th>\n",
       "      <th>12/21/16</th>\n",
       "      <th>12/22/16</th>\n",
       "      <th>12/23/16</th>\n",
       "      <th>12/27/16</th>\n",
       "      <th>12/28/16</th>\n",
       "      <th>12/29/16</th>\n",
       "      <th>12/30/16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.475141</td>\n",
       "      <td>1.368380</td>\n",
       "      <td>-0.673403</td>\n",
       "      <td>-2.341387</td>\n",
       "      <td>-0.155750</td>\n",
       "      <td>1.042349</td>\n",
       "      <td>0.640672</td>\n",
       "      <td>-1.995250</td>\n",
       "      <td>1.294572</td>\n",
       "      <td>-1.242466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716615</td>\n",
       "      <td>-0.203062</td>\n",
       "      <td>0.276064</td>\n",
       "      <td>-0.121699</td>\n",
       "      <td>0.437425</td>\n",
       "      <td>-0.469903</td>\n",
       "      <td>-0.056862</td>\n",
       "      <td>-0.317396</td>\n",
       "      <td>0.089624</td>\n",
       "      <td>-0.875225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.580423</td>\n",
       "      <td>1.388239</td>\n",
       "      <td>-1.437015</td>\n",
       "      <td>-2.703313</td>\n",
       "      <td>-1.650981</td>\n",
       "      <td>1.148467</td>\n",
       "      <td>0.652777</td>\n",
       "      <td>-1.954240</td>\n",
       "      <td>-0.460398</td>\n",
       "      <td>-1.636980</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.724003</td>\n",
       "      <td>-0.137565</td>\n",
       "      <td>1.831696</td>\n",
       "      <td>0.979929</td>\n",
       "      <td>-0.306396</td>\n",
       "      <td>-0.442096</td>\n",
       "      <td>-1.201565</td>\n",
       "      <td>-0.527809</td>\n",
       "      <td>0.078370</td>\n",
       "      <td>-0.451468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.992869</td>\n",
       "      <td>0.667182</td>\n",
       "      <td>-0.890569</td>\n",
       "      <td>-2.508405</td>\n",
       "      <td>-0.105895</td>\n",
       "      <td>2.079586</td>\n",
       "      <td>2.796908</td>\n",
       "      <td>-2.710470</td>\n",
       "      <td>1.899929</td>\n",
       "      <td>-1.675539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086678</td>\n",
       "      <td>-0.017345</td>\n",
       "      <td>0.086693</td>\n",
       "      <td>-0.451625</td>\n",
       "      <td>-0.576169</td>\n",
       "      <td>-0.175254</td>\n",
       "      <td>-0.263458</td>\n",
       "      <td>-0.900987</td>\n",
       "      <td>-0.053253</td>\n",
       "      <td>-1.430640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.858588</td>\n",
       "      <td>-1.550650</td>\n",
       "      <td>-3.252940</td>\n",
       "      <td>-0.904419</td>\n",
       "      <td>-0.329490</td>\n",
       "      <td>0.657897</td>\n",
       "      <td>0.544960</td>\n",
       "      <td>-2.436270</td>\n",
       "      <td>0.697640</td>\n",
       "      <td>-0.602221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080032</td>\n",
       "      <td>-0.601807</td>\n",
       "      <td>0.681775</td>\n",
       "      <td>0.345791</td>\n",
       "      <td>-0.987333</td>\n",
       "      <td>0.521566</td>\n",
       "      <td>0.013338</td>\n",
       "      <td>-0.816878</td>\n",
       "      <td>-0.606921</td>\n",
       "      <td>0.216216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.015182</td>\n",
       "      <td>-1.826014</td>\n",
       "      <td>-1.318764</td>\n",
       "      <td>-5.194612</td>\n",
       "      <td>-1.314689</td>\n",
       "      <td>0.821774</td>\n",
       "      <td>1.593171</td>\n",
       "      <td>-3.337763</td>\n",
       "      <td>1.497221</td>\n",
       "      <td>-2.746348</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.766543</td>\n",
       "      <td>0.411775</td>\n",
       "      <td>0.642092</td>\n",
       "      <td>-0.198829</td>\n",
       "      <td>-1.391772</td>\n",
       "      <td>0.547885</td>\n",
       "      <td>0.089166</td>\n",
       "      <td>-1.764586</td>\n",
       "      <td>-1.232189</td>\n",
       "      <td>0.149125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 252 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1/4/16    1/5/16    1/6/16    1/7/16    1/8/16   1/11/16   1/12/16  \\\n",
       "0 -0.475141  1.368380 -0.673403 -2.341387 -0.155750  1.042349  0.640672   \n",
       "1 -1.580423  1.388239 -1.437015 -2.703313 -1.650981  1.148467  0.652777   \n",
       "2 -2.992869  0.667182 -0.890569 -2.508405 -0.105895  2.079586  2.796908   \n",
       "3 -2.858588 -1.550650 -3.252940 -0.904419 -0.329490  0.657897  0.544960   \n",
       "4 -2.015182 -1.826014 -1.318764 -5.194612 -1.314689  0.821774  1.593171   \n",
       "\n",
       "    1/13/16   1/14/16   1/15/16    ...     12/16/16  12/19/16  12/20/16  \\\n",
       "0 -1.995250  1.294572 -1.242466    ...     0.716615 -0.203062  0.276064   \n",
       "1 -1.954240 -0.460398 -1.636980    ...    -0.724003 -0.137565  1.831696   \n",
       "2 -2.710470  1.899929 -1.675539    ...    -0.086678 -0.017345  0.086693   \n",
       "3 -2.436270  0.697640 -0.602221    ...     0.080032 -0.601807  0.681775   \n",
       "4 -3.337763  1.497221 -2.746348    ...    -0.766543  0.411775  0.642092   \n",
       "\n",
       "   12/21/16  12/22/16  12/23/16  12/27/16  12/28/16  12/29/16  12/30/16  \n",
       "0 -0.121699  0.437425 -0.469903 -0.056862 -0.317396  0.089624 -0.875225  \n",
       "1  0.979929 -0.306396 -0.442096 -1.201565 -0.527809  0.078370 -0.451468  \n",
       "2 -0.451625 -0.576169 -0.175254 -0.263458 -0.900987 -0.053253 -1.430640  \n",
       "3  0.345791 -0.987333  0.521566  0.013338 -0.816878 -0.606921  0.216216  \n",
       "4 -0.198829 -1.391772  0.547885  0.089166 -1.764586 -1.232189  0.149125  \n",
       "\n",
       "[5 rows x 252 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform price information into returns\n",
    "prices_second_day = prices.iloc[:,1:]\n",
    "prices_previous_day = prices.iloc[:,0:-1]\n",
    "daily_returns = prices_second_day/ prices_previous_day.values\n",
    "daily_returns = np.log(daily_returns)\n",
    "\n",
    "# Delete the columns with all 0s\n",
    "daily_returns = daily_returns.loc[:,(daily_returns!=0).any()] \n",
    "print(\"Dimension of the data: \", daily_returns.shape)\n",
    "\n",
    "# Convert from decimal to percentile\n",
    "daily_returns *= 100\n",
    "daily_returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POET Model\n",
    "Now that we have got the matrix of stock daily return, we are going to apply POET Model to generate/ estimate a more accurate covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1/4/16</th>\n",
       "      <th>1/5/16</th>\n",
       "      <th>1/6/16</th>\n",
       "      <th>1/7/16</th>\n",
       "      <th>1/8/16</th>\n",
       "      <th>1/11/16</th>\n",
       "      <th>1/12/16</th>\n",
       "      <th>1/13/16</th>\n",
       "      <th>1/14/16</th>\n",
       "      <th>1/15/16</th>\n",
       "      <th>...</th>\n",
       "      <th>12/16/16</th>\n",
       "      <th>12/19/16</th>\n",
       "      <th>12/20/16</th>\n",
       "      <th>12/21/16</th>\n",
       "      <th>12/22/16</th>\n",
       "      <th>12/23/16</th>\n",
       "      <th>12/27/16</th>\n",
       "      <th>12/28/16</th>\n",
       "      <th>12/29/16</th>\n",
       "      <th>12/30/16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.486987</td>\n",
       "      <td>1.356534</td>\n",
       "      <td>-0.685250</td>\n",
       "      <td>-2.353233</td>\n",
       "      <td>-0.167596</td>\n",
       "      <td>1.030503</td>\n",
       "      <td>0.628825</td>\n",
       "      <td>-2.007097</td>\n",
       "      <td>1.282726</td>\n",
       "      <td>-1.254313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704769</td>\n",
       "      <td>-0.214909</td>\n",
       "      <td>0.264217</td>\n",
       "      <td>-0.133545</td>\n",
       "      <td>0.425578</td>\n",
       "      <td>-0.481749</td>\n",
       "      <td>-0.068708</td>\n",
       "      <td>-0.329242</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>-0.887072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.498407</td>\n",
       "      <td>1.470254</td>\n",
       "      <td>-1.354999</td>\n",
       "      <td>-2.621297</td>\n",
       "      <td>-1.568965</td>\n",
       "      <td>1.230483</td>\n",
       "      <td>0.734792</td>\n",
       "      <td>-1.872224</td>\n",
       "      <td>-0.378382</td>\n",
       "      <td>-1.554964</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.641987</td>\n",
       "      <td>-0.055549</td>\n",
       "      <td>1.913712</td>\n",
       "      <td>1.061945</td>\n",
       "      <td>-0.224380</td>\n",
       "      <td>-0.360080</td>\n",
       "      <td>-1.119549</td>\n",
       "      <td>-0.445793</td>\n",
       "      <td>0.160386</td>\n",
       "      <td>-0.369452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.961876</td>\n",
       "      <td>0.698175</td>\n",
       "      <td>-0.859577</td>\n",
       "      <td>-2.477413</td>\n",
       "      <td>-0.074902</td>\n",
       "      <td>2.110578</td>\n",
       "      <td>2.827901</td>\n",
       "      <td>-2.679478</td>\n",
       "      <td>1.930921</td>\n",
       "      <td>-1.644547</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055685</td>\n",
       "      <td>0.013648</td>\n",
       "      <td>0.117685</td>\n",
       "      <td>-0.420632</td>\n",
       "      <td>-0.545177</td>\n",
       "      <td>-0.144262</td>\n",
       "      <td>-0.232466</td>\n",
       "      <td>-0.869994</td>\n",
       "      <td>-0.022260</td>\n",
       "      <td>-1.399647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.883627</td>\n",
       "      <td>-1.575689</td>\n",
       "      <td>-3.277980</td>\n",
       "      <td>-0.929459</td>\n",
       "      <td>-0.354529</td>\n",
       "      <td>0.632858</td>\n",
       "      <td>0.519921</td>\n",
       "      <td>-2.461309</td>\n",
       "      <td>0.672601</td>\n",
       "      <td>-0.627260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054992</td>\n",
       "      <td>-0.626847</td>\n",
       "      <td>0.656736</td>\n",
       "      <td>0.320751</td>\n",
       "      <td>-1.012372</td>\n",
       "      <td>0.496526</td>\n",
       "      <td>-0.011702</td>\n",
       "      <td>-0.841917</td>\n",
       "      <td>-0.631960</td>\n",
       "      <td>0.191177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.090380</td>\n",
       "      <td>-1.901212</td>\n",
       "      <td>-1.393963</td>\n",
       "      <td>-5.269811</td>\n",
       "      <td>-1.389887</td>\n",
       "      <td>0.746575</td>\n",
       "      <td>1.517973</td>\n",
       "      <td>-3.412962</td>\n",
       "      <td>1.422022</td>\n",
       "      <td>-2.821546</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.841741</td>\n",
       "      <td>0.336577</td>\n",
       "      <td>0.566894</td>\n",
       "      <td>-0.274028</td>\n",
       "      <td>-1.466971</td>\n",
       "      <td>0.472687</td>\n",
       "      <td>0.013968</td>\n",
       "      <td>-1.839785</td>\n",
       "      <td>-1.307387</td>\n",
       "      <td>0.073927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 252 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1/4/16    1/5/16    1/6/16    1/7/16    1/8/16   1/11/16   1/12/16  \\\n",
       "0 -0.486987  1.356534 -0.685250 -2.353233 -0.167596  1.030503  0.628825   \n",
       "1 -1.498407  1.470254 -1.354999 -2.621297 -1.568965  1.230483  0.734792   \n",
       "2 -2.961876  0.698175 -0.859577 -2.477413 -0.074902  2.110578  2.827901   \n",
       "3 -2.883627 -1.575689 -3.277980 -0.929459 -0.354529  0.632858  0.519921   \n",
       "4 -2.090380 -1.901212 -1.393963 -5.269811 -1.389887  0.746575  1.517973   \n",
       "\n",
       "    1/13/16   1/14/16   1/15/16    ...     12/16/16  12/19/16  12/20/16  \\\n",
       "0 -2.007097  1.282726 -1.254313    ...     0.704769 -0.214909  0.264217   \n",
       "1 -1.872224 -0.378382 -1.554964    ...    -0.641987 -0.055549  1.913712   \n",
       "2 -2.679478  1.930921 -1.644547    ...    -0.055685  0.013648  0.117685   \n",
       "3 -2.461309  0.672601 -0.627260    ...     0.054992 -0.626847  0.656736   \n",
       "4 -3.412962  1.422022 -2.821546    ...    -0.841741  0.336577  0.566894   \n",
       "\n",
       "   12/21/16  12/22/16  12/23/16  12/27/16  12/28/16  12/29/16  12/30/16  \n",
       "0 -0.133545  0.425578 -0.481749 -0.068708 -0.329242  0.077778 -0.887072  \n",
       "1  1.061945 -0.224380 -0.360080 -1.119549 -0.445793  0.160386 -0.369452  \n",
       "2 -0.420632 -0.545177 -0.144262 -0.232466 -0.869994 -0.022260 -1.399647  \n",
       "3  0.320751 -1.012372  0.496526 -0.011702 -0.841917 -0.631960  0.191177  \n",
       "4 -0.274028 -1.466971  0.472687  0.013968 -1.839785 -1.307387  0.073927  \n",
       "\n",
       "[5 rows x 252 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deduct row averages to get better performance\n",
    "de_meaned_mat = daily_returns.sub(daily_returns.mean(axis=1), axis=0)\n",
    "de_meaned_mat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix 1: PCA  on sample covariance matrix\n",
    "\n",
    "First we have to decide the number of principle components, i.e. K\n",
    "\n",
    "$\\hat{K} = argmin_{0 \\leq K_{1}\\leq M } log(\\frac{1}{pT}||Y - T^{-1} Y \\hat{F_{K_{1}}} \\hat{F^{'}_{K_{1}}}||^{2}_{F}) + K_{1}g(T,p)$\n",
    "\n",
    "$\\hat{F}_{K1}$ is a $T \\times K_1$ matrix whose columns are $\\sqrt{T}$ times the eigenvectors corresponding to the $K_1$ largest eigenvalues of the $T \\times T$ matrix $Y'Y$\n",
    "\n",
    "$g(T,p) = \\frac{p+T}{pT}log(\\frac{pT}{p+T})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K found:  1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "\n",
    "# First we look for k\n",
    "p = de_meaned_mat.shape[0]\n",
    "T = de_meaned_mat.shape[1]\n",
    "Y = de_meaned_mat.values #(50*252)\n",
    "\n",
    "def g(p, T):\n",
    "    return (p+T)* math.log((p*T)/(p+T))/(p*T)\n",
    "\n",
    "min_evaluator = np.inf\n",
    "estimated_k = 0\n",
    "\n",
    "for k in range(1,10):\n",
    "    pca = PCA(n_components=k)\n",
    "    result = pca.fit((Y.T) @ Y)\n",
    "    F = (pca.components_.T)\n",
    "    evaluator = math.log(1/(p*T)* np.square(np.linalg.norm(Y - (1/T)*(Y @ np.dot(F,F.T))))) + k*g(p,T)\n",
    "    #print(evaluator)\n",
    "    if evaluator < min_evaluator:\n",
    "        min_evaluator = evaluator\n",
    "        estimated_k = k\n",
    "        \n",
    "print(\"K found: \",estimated_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know $Var(C_i)$ is the eigenvalue of the covariance matrix for $X_i$, and the eigenvector of the matrix is the vector for coefficients.\n",
    "\n",
    "$ \\sum_{i=1}^{K} \\hat{\\lambda}_{i} \\hat{\\xi}_{i} \\hat{\\xi}_{i}^{'} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get matrix 1\n",
    "e_values, e_vectors = np.linalg.eig(np.cov(Y)) # 50*1\n",
    "matrix1 = np.zeros([p,p])\n",
    "for k in range(estimated_k):\n",
    "    matrix1 += e_values[k] * (e_vectors[:,k].reshape(p,1) @ e_vectors[:,k].reshape(1,p)) # eigen-decomposition\n",
    "    \n",
    "# Now that we've got matrix1. We subtract matrix1 from the covariance matrix to get matrix2   \n",
    "matrix2 = np.cov(Y) - matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.826631</td>\n",
       "      <td>0.312731</td>\n",
       "      <td>0.444077</td>\n",
       "      <td>-0.036779</td>\n",
       "      <td>0.013314</td>\n",
       "      <td>0.177122</td>\n",
       "      <td>0.109953</td>\n",
       "      <td>0.355197</td>\n",
       "      <td>0.126759</td>\n",
       "      <td>0.119455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098820</td>\n",
       "      <td>0.043753</td>\n",
       "      <td>0.331352</td>\n",
       "      <td>0.160522</td>\n",
       "      <td>0.231496</td>\n",
       "      <td>0.394734</td>\n",
       "      <td>0.388187</td>\n",
       "      <td>0.455354</td>\n",
       "      <td>0.290470</td>\n",
       "      <td>0.039301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.312731</td>\n",
       "      <td>1.623905</td>\n",
       "      <td>0.681817</td>\n",
       "      <td>0.044976</td>\n",
       "      <td>0.099122</td>\n",
       "      <td>0.135710</td>\n",
       "      <td>-0.034607</td>\n",
       "      <td>0.313168</td>\n",
       "      <td>0.439603</td>\n",
       "      <td>0.388972</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.518991</td>\n",
       "      <td>-0.155665</td>\n",
       "      <td>0.271331</td>\n",
       "      <td>0.089046</td>\n",
       "      <td>-0.032234</td>\n",
       "      <td>0.100307</td>\n",
       "      <td>0.047703</td>\n",
       "      <td>0.055067</td>\n",
       "      <td>0.110980</td>\n",
       "      <td>-0.005698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.444077</td>\n",
       "      <td>0.681817</td>\n",
       "      <td>1.289297</td>\n",
       "      <td>-0.003301</td>\n",
       "      <td>0.079910</td>\n",
       "      <td>0.261665</td>\n",
       "      <td>0.126382</td>\n",
       "      <td>0.481544</td>\n",
       "      <td>0.421205</td>\n",
       "      <td>0.267693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.282216</td>\n",
       "      <td>-0.013023</td>\n",
       "      <td>0.494574</td>\n",
       "      <td>0.165073</td>\n",
       "      <td>0.187681</td>\n",
       "      <td>0.383905</td>\n",
       "      <td>0.531870</td>\n",
       "      <td>0.350648</td>\n",
       "      <td>0.194926</td>\n",
       "      <td>0.248134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.036779</td>\n",
       "      <td>0.044976</td>\n",
       "      <td>-0.003301</td>\n",
       "      <td>1.787338</td>\n",
       "      <td>0.621465</td>\n",
       "      <td>0.085582</td>\n",
       "      <td>-0.233200</td>\n",
       "      <td>-0.164227</td>\n",
       "      <td>-0.071534</td>\n",
       "      <td>0.069026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.325716</td>\n",
       "      <td>-0.058755</td>\n",
       "      <td>-0.170267</td>\n",
       "      <td>-0.061293</td>\n",
       "      <td>-0.283128</td>\n",
       "      <td>-0.226225</td>\n",
       "      <td>-0.003512</td>\n",
       "      <td>-0.211230</td>\n",
       "      <td>-0.443572</td>\n",
       "      <td>-0.406958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013314</td>\n",
       "      <td>0.099122</td>\n",
       "      <td>0.079910</td>\n",
       "      <td>0.621465</td>\n",
       "      <td>1.569984</td>\n",
       "      <td>-0.054189</td>\n",
       "      <td>-0.282033</td>\n",
       "      <td>-0.077135</td>\n",
       "      <td>-0.144830</td>\n",
       "      <td>-0.081115</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.656807</td>\n",
       "      <td>0.090061</td>\n",
       "      <td>-0.239516</td>\n",
       "      <td>-0.041189</td>\n",
       "      <td>-0.471650</td>\n",
       "      <td>-0.360813</td>\n",
       "      <td>-0.353233</td>\n",
       "      <td>-0.201498</td>\n",
       "      <td>-0.548588</td>\n",
       "      <td>-0.180713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.826631  0.312731  0.444077 -0.036779  0.013314  0.177122  0.109953   \n",
       "1  0.312731  1.623905  0.681817  0.044976  0.099122  0.135710 -0.034607   \n",
       "2  0.444077  0.681817  1.289297 -0.003301  0.079910  0.261665  0.126382   \n",
       "3 -0.036779  0.044976 -0.003301  1.787338  0.621465  0.085582 -0.233200   \n",
       "4  0.013314  0.099122  0.079910  0.621465  1.569984 -0.054189 -0.282033   \n",
       "\n",
       "         7         8         9     ...           40        41        42  \\\n",
       "0  0.355197  0.126759  0.119455    ...    -0.098820  0.043753  0.331352   \n",
       "1  0.313168  0.439603  0.388972    ...    -0.518991 -0.155665  0.271331   \n",
       "2  0.481544  0.421205  0.267693    ...    -0.282216 -0.013023  0.494574   \n",
       "3 -0.164227 -0.071534  0.069026    ...    -0.325716 -0.058755 -0.170267   \n",
       "4 -0.077135 -0.144830 -0.081115    ...    -0.656807  0.090061 -0.239516   \n",
       "\n",
       "         43        44        45        46        47        48        49  \n",
       "0  0.160522  0.231496  0.394734  0.388187  0.455354  0.290470  0.039301  \n",
       "1  0.089046 -0.032234  0.100307  0.047703  0.055067  0.110980 -0.005698  \n",
       "2  0.165073  0.187681  0.383905  0.531870  0.350648  0.194926  0.248134  \n",
       "3 -0.061293 -0.283128 -0.226225 -0.003512 -0.211230 -0.443572 -0.406958  \n",
       "4 -0.041189 -0.471650 -0.360813 -0.353233 -0.201498 -0.548588 -0.180713  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(matrix2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 50)\n",
      "(50, 50)\n"
     ]
    }
   ],
   "source": [
    "print(matrix1.shape)\n",
    "print(matrix2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix 2: Thresholding\n",
    "\n",
    "$\\tau_{ij} = Cw_T\\sqrt{\\hat{\\theta}_{ij}}$\n",
    "\n",
    "- $\\omega_{T}= \\frac{1}{\\sqrt{p}} + \\sqrt( \\frac{log(p)}{T}) $  (Constant)\n",
    "\n",
    "- $\\hat{\\theta}_{ij}=\\frac{1}{T}\\sum^T _{t=1}(\\hat{u}_{it}\\hat{u}_{jt}-\\hat{\\sigma}_{ij})^2$ \n",
    "\n",
    "  $\\hat{u}_{it} = y_{it} - bf$  # To be found using least square method\n",
    "  \n",
    "  $\\hat{\\sigma}_{ij} = \\frac{1}{T}\\sum_{t=1}^{T}\\hat{u}_{it}\\hat{u}_{jt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find omega\n",
    "omega = 1/ np.sqrt(p) + np.sqrt(np.log(p)/T)\n",
    "\n",
    "# find matrix of theta\n",
    "I = np.zeros([p,p])\n",
    "for i in range(p):\n",
    "    I[i][i] = 1\n",
    "hat_u_mat = (I - (e_vectors[:,0:estimated_k].reshape(50,estimated_k) @ e_vectors[:,0:estimated_k].reshape(50,estimated_k).T)) @ Y # least sqaure error\n",
    "        \n",
    "hat_sigma_mat = np.empty([p,p])\n",
    "for i in range(p):\n",
    "    for j in range(p):\n",
    "        value = 0\n",
    "        for t in range(T):\n",
    "            value += hat_u_mat[i][t] * hat_u_mat[j][t]\n",
    "        hat_sigma_mat[i][j] = value / T\n",
    "\n",
    "hat_theta_mat = np.zeros([p,p])\n",
    "for i in range(p):\n",
    "    for j in range(p):\n",
    "        value = 0\n",
    "        for t in range(T):\n",
    "            value += (hat_u_mat[i][t] * hat_u_mat[j][t] - hat_sigma_mat[i][j])**2\n",
    "        hat_theta_mat[i][j] = value / T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Find C__\n",
    "1. decide $C_{min}$ by choosing the smallest threshold C that guarantees the covaricance matrix is positive definite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "# We perform thresholding on the covariance matrix, testing different values of C\n",
    "eigen_list = []\n",
    "x_axis = []\n",
    "def is_pos_def(mat):\n",
    "    eigen_list.append(min(np.linalg.eigvals(mat)))\n",
    "    if min(np.linalg.eigvals(mat))> 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def thresholding(C,mat): \n",
    "    c_mat = copy.deepcopy(mat)\n",
    "    for i in range(p):\n",
    "        for j in range(p):\n",
    "            if i==j:\n",
    "                continue\n",
    "            elif c_mat[i][j] < C * omega * np.sqrt(hat_theta_mat[i][j]):\n",
    "                c_mat[i][j] = 0\n",
    "    if is_pos_def(c_mat):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def find_min_C(mat):\n",
    "    for C in range(0,3):\n",
    "        if thresholding(C,mat):\n",
    "            return C\n",
    "        \n",
    "for C in np.arange(0,3,0.01):\n",
    "    x_axis.append(C)\n",
    "    thresholding(C,matrix2)\n",
    "\n",
    "plt.plot(x_axis, eigen_list,[0,3],[0,0],'--')\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(r\"$\\lambda_{min}$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Now that we've found min_C to be 0, we continue to find the optimal C using cross-validation\n",
    "\n",
    "$C^* = argmin \\frac{1}{H} \\sum _{j=1}^{H}||\\hat{\\sum}_{u}^{\\tau,j}(C) - \\hat{\\sum}_{u}^{j}||_F ^2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal C found:  39\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# We split the residuals obtained by PCA into two parts\n",
    "opt_C = 0\n",
    "hat_u_mat = hat_u_mat.T\n",
    "\n",
    "\n",
    "def do_thresholding(C,c_mat): \n",
    "    for i in range(p):\n",
    "        for j in range(p):\n",
    "            if i==j:\n",
    "                continue\n",
    "            elif np.abs(c_mat[i][j]) < C * omega * np.sqrt(hat_theta_mat[i][j]):\n",
    "                c_mat[i][j] = 0\n",
    "                \n",
    "min_error = np.inf                \n",
    "for C in np.arange(2, 50, 1):\n",
    "    sum_error = 0\n",
    "    H = 10\n",
    "    num = H\n",
    "    for h in range(H):\n",
    "        train, test = train_test_split(hat_u_mat,test_size=0.5)\n",
    "        cov_mat_train = np.cov(train,rowvar=False)\n",
    "        do_thresholding(C,cov_mat_train)\n",
    "#         if not is_pos_def(cov_mat_train):\n",
    "#             num -= 1\n",
    "#             continue\n",
    "        cov_mat_test = np.cov(test,rowvar=False)\n",
    "        sum_error += (np.linalg.norm(cov_mat_train-cov_mat_test))**2\n",
    "    #if num != 0:\n",
    "    sum_error /= num\n",
    "#     else:\n",
    "#         sum_error = np.inf\n",
    "    if sum_error < min_error:\n",
    "        min_error = sum_error\n",
    "        opt_C = C\n",
    "\n",
    "print(\"Optimal C found: \", opt_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Retrieve the same output as R package:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_l, e_v = np.linalg.eig(Y.T @ Y)\n",
    "LamPCA = Y @ e_v[:,:1] * np.sqrt(T) / T\n",
    "Lowrank = LamPCA @ LamPCA.T\n",
    "SigmaU = matrix2\n",
    "SigmaY = Lowrank + matrix2\n",
    "Factors = e_v[:,:1].T\n",
    "Loadings = LamPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.826631</td>\n",
       "      <td>0.312731</td>\n",
       "      <td>0.444077</td>\n",
       "      <td>-0.036779</td>\n",
       "      <td>0.013314</td>\n",
       "      <td>0.177122</td>\n",
       "      <td>0.109953</td>\n",
       "      <td>0.355197</td>\n",
       "      <td>0.126759</td>\n",
       "      <td>0.119455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098820</td>\n",
       "      <td>0.043753</td>\n",
       "      <td>0.331352</td>\n",
       "      <td>0.160522</td>\n",
       "      <td>0.231496</td>\n",
       "      <td>0.394734</td>\n",
       "      <td>0.388187</td>\n",
       "      <td>0.455354</td>\n",
       "      <td>0.290470</td>\n",
       "      <td>0.039301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.312731</td>\n",
       "      <td>1.623905</td>\n",
       "      <td>0.681817</td>\n",
       "      <td>0.044976</td>\n",
       "      <td>0.099122</td>\n",
       "      <td>0.135710</td>\n",
       "      <td>-0.034607</td>\n",
       "      <td>0.313168</td>\n",
       "      <td>0.439603</td>\n",
       "      <td>0.388972</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.518991</td>\n",
       "      <td>-0.155665</td>\n",
       "      <td>0.271331</td>\n",
       "      <td>0.089046</td>\n",
       "      <td>-0.032234</td>\n",
       "      <td>0.100307</td>\n",
       "      <td>0.047703</td>\n",
       "      <td>0.055067</td>\n",
       "      <td>0.110980</td>\n",
       "      <td>-0.005698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.444077</td>\n",
       "      <td>0.681817</td>\n",
       "      <td>1.289297</td>\n",
       "      <td>-0.003301</td>\n",
       "      <td>0.079910</td>\n",
       "      <td>0.261665</td>\n",
       "      <td>0.126382</td>\n",
       "      <td>0.481544</td>\n",
       "      <td>0.421205</td>\n",
       "      <td>0.267693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.282216</td>\n",
       "      <td>-0.013023</td>\n",
       "      <td>0.494574</td>\n",
       "      <td>0.165073</td>\n",
       "      <td>0.187681</td>\n",
       "      <td>0.383905</td>\n",
       "      <td>0.531870</td>\n",
       "      <td>0.350648</td>\n",
       "      <td>0.194926</td>\n",
       "      <td>0.248134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.036779</td>\n",
       "      <td>0.044976</td>\n",
       "      <td>-0.003301</td>\n",
       "      <td>1.787338</td>\n",
       "      <td>0.621465</td>\n",
       "      <td>0.085582</td>\n",
       "      <td>-0.233200</td>\n",
       "      <td>-0.164227</td>\n",
       "      <td>-0.071534</td>\n",
       "      <td>0.069026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.325716</td>\n",
       "      <td>-0.058755</td>\n",
       "      <td>-0.170267</td>\n",
       "      <td>-0.061293</td>\n",
       "      <td>-0.283128</td>\n",
       "      <td>-0.226225</td>\n",
       "      <td>-0.003512</td>\n",
       "      <td>-0.211230</td>\n",
       "      <td>-0.443572</td>\n",
       "      <td>-0.406958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013314</td>\n",
       "      <td>0.099122</td>\n",
       "      <td>0.079910</td>\n",
       "      <td>0.621465</td>\n",
       "      <td>1.569984</td>\n",
       "      <td>-0.054189</td>\n",
       "      <td>-0.282033</td>\n",
       "      <td>-0.077135</td>\n",
       "      <td>-0.144830</td>\n",
       "      <td>-0.081115</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.656807</td>\n",
       "      <td>0.090061</td>\n",
       "      <td>-0.239516</td>\n",
       "      <td>-0.041189</td>\n",
       "      <td>-0.471650</td>\n",
       "      <td>-0.360813</td>\n",
       "      <td>-0.353233</td>\n",
       "      <td>-0.201498</td>\n",
       "      <td>-0.548588</td>\n",
       "      <td>-0.180713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.826631  0.312731  0.444077 -0.036779  0.013314  0.177122  0.109953   \n",
       "1  0.312731  1.623905  0.681817  0.044976  0.099122  0.135710 -0.034607   \n",
       "2  0.444077  0.681817  1.289297 -0.003301  0.079910  0.261665  0.126382   \n",
       "3 -0.036779  0.044976 -0.003301  1.787338  0.621465  0.085582 -0.233200   \n",
       "4  0.013314  0.099122  0.079910  0.621465  1.569984 -0.054189 -0.282033   \n",
       "\n",
       "         7         8         9     ...           40        41        42  \\\n",
       "0  0.355197  0.126759  0.119455    ...    -0.098820  0.043753  0.331352   \n",
       "1  0.313168  0.439603  0.388972    ...    -0.518991 -0.155665  0.271331   \n",
       "2  0.481544  0.421205  0.267693    ...    -0.282216 -0.013023  0.494574   \n",
       "3 -0.164227 -0.071534  0.069026    ...    -0.325716 -0.058755 -0.170267   \n",
       "4 -0.077135 -0.144830 -0.081115    ...    -0.656807  0.090061 -0.239516   \n",
       "\n",
       "         43        44        45        46        47        48        49  \n",
       "0  0.160522  0.231496  0.394734  0.388187  0.455354  0.290470  0.039301  \n",
       "1  0.089046 -0.032234  0.100307  0.047703  0.055067  0.110980 -0.005698  \n",
       "2  0.165073  0.187681  0.383905  0.531870  0.350648  0.194926  0.248134  \n",
       "3 -0.061293 -0.283128 -0.226225 -0.003512 -0.211230 -0.443572 -0.406958  \n",
       "4 -0.041189 -0.471650 -0.360813 -0.353233 -0.201498 -0.548588 -0.180713  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(SigmaU).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.9304636240225836+0j)</td>\n",
       "      <td>(0.5077153322260161+0j)</td>\n",
       "      <td>(0.627604963371607+0j)</td>\n",
       "      <td>(0.22885383007331722+0j)</td>\n",
       "      <td>(0.41482811819167564+0j)</td>\n",
       "      <td>(0.5130466932002842+0j)</td>\n",
       "      <td>(0.42195874392289623+0j)</td>\n",
       "      <td>(0.6979670247893937+0j)</td>\n",
       "      <td>(0.4647810132559606+0j)</td>\n",
       "      <td>(0.6428583020566264+0j)</td>\n",
       "      <td>...</td>\n",
       "      <td>(0.6320446966764155+0j)</td>\n",
       "      <td>(0.4435231651680193+0j)</td>\n",
       "      <td>(0.41199076785456656+0j)</td>\n",
       "      <td>(0.3229449509711952+0j)</td>\n",
       "      <td>(0.3213525664340985+0j)</td>\n",
       "      <td>(0.4849302618714857+0j)</td>\n",
       "      <td>(0.47094483945635485+0j)</td>\n",
       "      <td>(0.531559605342603+0j)</td>\n",
       "      <td>(0.424289986383445+0j)</td>\n",
       "      <td>(0.10488245408520323+0j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.5077153322260161+0j)</td>\n",
       "      <td>(1.9900602063543644+0j)</td>\n",
       "      <td>(1.0264595840179125+0j)</td>\n",
       "      <td>(0.5438005773482388+0j)</td>\n",
       "      <td>(0.8531143409974598+0j)</td>\n",
       "      <td>(0.7665341222622605+0j)</td>\n",
       "      <td>(0.5513003792050375+0j)</td>\n",
       "      <td>(0.9568479546512396+0j)</td>\n",
       "      <td>(1.0743654658048225+0j)</td>\n",
       "      <td>(1.3718570121575238+0j)</td>\n",
       "      <td>...</td>\n",
       "      <td>(0.8534800864160965+0j)</td>\n",
       "      <td>(0.5950526400902953+0j)</td>\n",
       "      <td>(0.4227604519750421+0j)</td>\n",
       "      <td>(0.3940557740957246+0j)</td>\n",
       "      <td>(0.13650528034406098+0j)</td>\n",
       "      <td>(0.2696840166364288+0j)</td>\n",
       "      <td>(0.2031120741682848+0j)</td>\n",
       "      <td>(0.19817213281209967+0j)</td>\n",
       "      <td>(0.3622778689669173+0j)</td>\n",
       "      <td>(0.11745647139822527+0j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.627604963371607+0j)</td>\n",
       "      <td>(1.0264595840179125+0j)</td>\n",
       "      <td>(1.6136897383441309+0j)</td>\n",
       "      <td>(0.46621521551491757+0j)</td>\n",
       "      <td>(0.7896014213698941+0j)</td>\n",
       "      <td>(0.855424767784154+0j)</td>\n",
       "      <td>(0.6778645920967572+0j)</td>\n",
       "      <td>(1.08740418242046+0j)</td>\n",
       "      <td>(1.018672898781839+0j)</td>\n",
       "      <td>(1.1928291447761525+0j)</td>\n",
       "      <td>...</td>\n",
       "      <td>(1.0096150962453423+0j)</td>\n",
       "      <td>(0.6935865396790878+0j)</td>\n",
       "      <td>(0.637106374818597+0j)</td>\n",
       "      <td>(0.45216156121485035+0j)</td>\n",
       "      <td>(0.346506175624748+0j)</td>\n",
       "      <td>(0.543330212731924+0j)</td>\n",
       "      <td>(0.6781487177423106+0j)</td>\n",
       "      <td>(0.4853449981464098+0j)</td>\n",
       "      <td>(0.43145865356552815+0j)</td>\n",
       "      <td>(0.3640529325241617+0j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.22885383007331722+0j)</td>\n",
       "      <td>(0.5438005773482388+0j)</td>\n",
       "      <td>(0.46621521551491757+0j)</td>\n",
       "      <td>(2.466902053035121+0j)</td>\n",
       "      <td>(1.648651246639824+0j)</td>\n",
       "      <td>(0.9449718923517008+0j)</td>\n",
       "      <td>(0.5649990061900665+0j)</td>\n",
       "      <td>(0.7126765560612635+0j)</td>\n",
       "      <td>(0.7932223240706084+0j)</td>\n",
       "      <td>(1.40803949783122+0j)</td>\n",
       "      <td>...</td>\n",
       "      <td>(1.5440422528260442+0j)</td>\n",
       "      <td>(0.9639696794419819+0j)</td>\n",
       "      <td>(0.03602952049915306+0j)</td>\n",
       "      <td>(0.3542310674222204+0j)</td>\n",
       "      <td>(-0.053249473152115784+0j)</td>\n",
       "      <td>(0.004522585992970007+0j)</td>\n",
       "      <td>(0.20820683735396056+0j)</td>\n",
       "      <td>(-0.016273597567319498+0j)</td>\n",
       "      <td>(-0.10122136453936958+0j)</td>\n",
       "      <td>(-0.23918144259961832+0j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.41482811819167564+0j)</td>\n",
       "      <td>(0.8531143409974598+0j)</td>\n",
       "      <td>(0.7896014213698941+0j)</td>\n",
       "      <td>(1.648651246639824+0j)</td>\n",
       "      <td>(3.1226158107947217+0j)</td>\n",
       "      <td>(1.2448124051062894+0j)</td>\n",
       "      <td>(0.9244755576197248+0j)</td>\n",
       "      <td>(1.248339069356279+0j)</td>\n",
       "      <td>(1.1622827755438228+0j)</td>\n",
       "      <td>(1.9428554248111733+0j)</td>\n",
       "      <td>...</td>\n",
       "      <td>(2.169404212410495+0j)</td>\n",
       "      <td>(1.6359486643170724+0j)</td>\n",
       "      <td>(0.07230893857368559+0j)</td>\n",
       "      <td>(0.586891184138593+0j)</td>\n",
       "      <td>(-0.12418001913209875+0j)</td>\n",
       "      <td>(-0.012029718124342281+0j)</td>\n",
       "      <td>(-0.033212136847101226+0j)</td>\n",
       "      <td>(0.09318547606816546+0j)</td>\n",
       "      <td>(-0.031111944844041783+0j)</td>\n",
       "      <td>(0.0728882919094472+0j)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0                        1   \\\n",
       "0   (0.9304636240225836+0j)  (0.5077153322260161+0j)   \n",
       "1   (0.5077153322260161+0j)  (1.9900602063543644+0j)   \n",
       "2    (0.627604963371607+0j)  (1.0264595840179125+0j)   \n",
       "3  (0.22885383007331722+0j)  (0.5438005773482388+0j)   \n",
       "4  (0.41482811819167564+0j)  (0.8531143409974598+0j)   \n",
       "\n",
       "                         2                         3   \\\n",
       "0    (0.627604963371607+0j)  (0.22885383007331722+0j)   \n",
       "1   (1.0264595840179125+0j)   (0.5438005773482388+0j)   \n",
       "2   (1.6136897383441309+0j)  (0.46621521551491757+0j)   \n",
       "3  (0.46621521551491757+0j)    (2.466902053035121+0j)   \n",
       "4   (0.7896014213698941+0j)    (1.648651246639824+0j)   \n",
       "\n",
       "                         4                        5   \\\n",
       "0  (0.41482811819167564+0j)  (0.5130466932002842+0j)   \n",
       "1   (0.8531143409974598+0j)  (0.7665341222622605+0j)   \n",
       "2   (0.7896014213698941+0j)   (0.855424767784154+0j)   \n",
       "3    (1.648651246639824+0j)  (0.9449718923517008+0j)   \n",
       "4   (3.1226158107947217+0j)  (1.2448124051062894+0j)   \n",
       "\n",
       "                         6                        7                        8   \\\n",
       "0  (0.42195874392289623+0j)  (0.6979670247893937+0j)  (0.4647810132559606+0j)   \n",
       "1   (0.5513003792050375+0j)  (0.9568479546512396+0j)  (1.0743654658048225+0j)   \n",
       "2   (0.6778645920967572+0j)    (1.08740418242046+0j)   (1.018672898781839+0j)   \n",
       "3   (0.5649990061900665+0j)  (0.7126765560612635+0j)  (0.7932223240706084+0j)   \n",
       "4   (0.9244755576197248+0j)   (1.248339069356279+0j)  (1.1622827755438228+0j)   \n",
       "\n",
       "                        9             ...              \\\n",
       "0  (0.6428583020566264+0j)            ...               \n",
       "1  (1.3718570121575238+0j)            ...               \n",
       "2  (1.1928291447761525+0j)            ...               \n",
       "3    (1.40803949783122+0j)            ...               \n",
       "4  (1.9428554248111733+0j)            ...               \n",
       "\n",
       "                        40                       41                        42  \\\n",
       "0  (0.6320446966764155+0j)  (0.4435231651680193+0j)  (0.41199076785456656+0j)   \n",
       "1  (0.8534800864160965+0j)  (0.5950526400902953+0j)   (0.4227604519750421+0j)   \n",
       "2  (1.0096150962453423+0j)  (0.6935865396790878+0j)    (0.637106374818597+0j)   \n",
       "3  (1.5440422528260442+0j)  (0.9639696794419819+0j)  (0.03602952049915306+0j)   \n",
       "4   (2.169404212410495+0j)  (1.6359486643170724+0j)  (0.07230893857368559+0j)   \n",
       "\n",
       "                         43                          44  \\\n",
       "0   (0.3229449509711952+0j)     (0.3213525664340985+0j)   \n",
       "1   (0.3940557740957246+0j)    (0.13650528034406098+0j)   \n",
       "2  (0.45216156121485035+0j)      (0.346506175624748+0j)   \n",
       "3   (0.3542310674222204+0j)  (-0.053249473152115784+0j)   \n",
       "4    (0.586891184138593+0j)   (-0.12418001913209875+0j)   \n",
       "\n",
       "                           45                          46  \\\n",
       "0     (0.4849302618714857+0j)    (0.47094483945635485+0j)   \n",
       "1     (0.2696840166364288+0j)     (0.2031120741682848+0j)   \n",
       "2      (0.543330212731924+0j)     (0.6781487177423106+0j)   \n",
       "3   (0.004522585992970007+0j)    (0.20820683735396056+0j)   \n",
       "4  (-0.012029718124342281+0j)  (-0.033212136847101226+0j)   \n",
       "\n",
       "                           47                          48  \\\n",
       "0      (0.531559605342603+0j)      (0.424289986383445+0j)   \n",
       "1    (0.19817213281209967+0j)     (0.3622778689669173+0j)   \n",
       "2     (0.4853449981464098+0j)    (0.43145865356552815+0j)   \n",
       "3  (-0.016273597567319498+0j)   (-0.10122136453936958+0j)   \n",
       "4    (0.09318547606816546+0j)  (-0.031111944844041783+0j)   \n",
       "\n",
       "                          49  \n",
       "0   (0.10488245408520323+0j)  \n",
       "1   (0.11745647139822527+0j)  \n",
       "2    (0.3640529325241617+0j)  \n",
       "3  (-0.23918144259961832+0j)  \n",
       "4    (0.0728882919094472+0j)  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(SigmaY).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk Analysis: Markowitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "risk_POET:  [[0.00145876+0.j]]\n",
      "risk_DIAG:  [[0.0030859+0.j]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cov_daily = np.cov(daily_returns.values.T, rowvar=False)\n",
    "e_daily = np.linalg.eigvals(cov_daily)\n",
    "plt.plot(e_daily,'o')\n",
    "\n",
    "def calculate_weights(cov_mat, mu):\n",
    "    one_vector = np.ones([1,cov_mat.shape[1]]).T # 50 by 1\n",
    "    inv_cov = np.linalg.inv(cov_mat) # 50 by 50\n",
    "    mu_target = 0.04\n",
    "    \n",
    "    A = mu @ inv_cov @ one_vector \n",
    "    B = mu @ inv_cov @ mu.T \n",
    "    C = one_vector.T @ inv_cov @ one_vector\n",
    "    D = B*C - A*A\n",
    "    \n",
    "    w_eff = ((B * inv_cov @ one_vector).reshape(50,1) - (A * inv_cov @ mu.T).reshape(50,1) +\n",
    "             mu_target * ((C*inv_cov@mu.T).reshape(50,1) - (A*inv_cov@one_vector).reshape(50,1)))/D\n",
    "\n",
    "    return w_eff\n",
    "\n",
    "def calculate_risk(w_eff):\n",
    "    return w_eff.T / T @ cov_daily @ w_eff\n",
    "\n",
    "portfolio_weights_diag = np.diag(np.diag(cov_daily))\n",
    "\n",
    "# risk-adjusted return\n",
    "alpha = daily_returns - Loadings @ Factors\n",
    "alpha = np.mean(alpha,axis=1)\n",
    "\n",
    "w = calculate_weights(SigmaY, alpha)\n",
    "w2 = calculate_weights(portfolio_weights_diag, alpha)\n",
    "\n",
    "risk_POET = calculate_risk(w)\n",
    "risk_DIAG = calculate_risk(w2)\n",
    "\n",
    "print(\"risk_POET: \",risk_POET)\n",
    "print(\"risk_DIAG: \",risk_DIAG)\n",
    "\n",
    "plt.xlabel(\"index\")\n",
    "plt.ylabel(\"eigenvalues of daily_return\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Code: Banding\n",
    "Implementation of Banding model. k found = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def banding(mat):\n",
    "    # Estimate k using the empirical risk function \n",
    "    min_k = (np.inf, 0)\n",
    "\n",
    "    for i in range (1,8): # most of the time number of variables kept is less than 8\n",
    "        risk = 0\n",
    "        random_test = 1000\n",
    "        for j in range(random_test): # Take the average of 1000 simulations\n",
    "            # Divide the dataset into two parts\n",
    "            X_train, X_test = train_test_split(mat)\n",
    "            estimiated_cov = np.cov(X_train, rowvar=False) \n",
    "            # do banding \n",
    "            for m in range(estimiated_cov.shape[1]):\n",
    "                for n in range(estimiated_cov.shape[1]):\n",
    "                    if abs(m-n)>i:\n",
    "                        estimiated_cov[m,n] = 0\n",
    "            test_cov = np.cov(X_test, rowvar=False)\n",
    "            # calculate the estimated risk\n",
    "            risk += np.linalg.norm(estimiated_cov-test_cov) # frobenius norm\n",
    "        #Take the average of risk\n",
    "        risk /= random_test\n",
    "        if (risk < min_k[0]):\n",
    "            min_k = (risk, i)\n",
    "            \n",
    "    k = min_k[1]         \n",
    "\n",
    "    # Conduct banding: set all entries where |i-j|>k to 0\n",
    "    cov_mat = np.cov(mat, rowvar=False)\n",
    "    # do banding \n",
    "    for m in range(cov_mat.shape[1]):\n",
    "        for n in range(cov_mat.shape[1]):\n",
    "            if abs(m-n)>k:\n",
    "                cov_mat[m,n] = 0\n",
    "    return cov_mat, k\n",
    "\n",
    "cov_mat, k = banding(de_meaned_mat)\n",
    "print(\"k = \", k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda]",
   "language": "python",
   "name": "conda-env-Anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
